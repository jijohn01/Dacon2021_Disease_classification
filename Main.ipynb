{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Effi_CutMix.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMy2laY032aOiDNbyzkLb7C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"d0fV4ebcdncG"},"source":["**Effi_CutMix.py**\n","\n","**.. ├ cutmix**\n","\n","**…. ├ cutmix.py**\n","\n","**…. └ utils.py**\n","\n",".. ├ models\n","\n",".. ├ train_imgs\n","\n",".. ├ test_imgs\n","\n",".. ├ train.csv\n","\n",".. ├ test.csv\n","\n",".. └ sample_submission.csv"]},{"cell_type":"markdown","metadata":{"id":"aN0drJ0mVBun"},"source":["# 0. cutmix 폴더 내 코드\n","\n","> cutmix.py\n","\n"]},{"cell_type":"code","metadata":{"id":"TmwuIc_LXRbO"},"source":["import numpy as np\n","import random\n","from torch.utils.data.dataset import Dataset\n","\n","from cutmix.utils import onehot, rand_bbox\n","\n","class CutMix(Dataset):\n","    def __init__(self, dataset, num_class, num_mix=1, beta=1., prob=1.0):\n","        self.dataset = dataset\n","        self.num_class = num_class\n","        self.num_mix = num_mix\n","        self.beta = beta\n","        self.prob = prob\n","\n","    def __getitem__(self, index):\n","        img = self.dataset[index]['img']\n","        lb = self.dataset[index]['label']\n","        lb_onehot = onehot(self.num_class, lb)\n","\n","        for _ in range(self.num_mix):\n","            r = np.random.rand(1)\n","            if self.beta <= 0 or r > self.prob:\n","                continue\n","\n","            # generate mixed sample\n","            lam = np.random.beta(self.beta, self.beta)\n","            rand_index = random.choice(range(len(self)))\n","\n","            img2 = self.dataset[rand_index]['img']\n","            lb2 = self.dataset[rand_index]['label']\n","            lb2_onehot = onehot(self.num_class, lb2)\n","\n","            bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n","            img[:, bbx1:bbx2, bby1:bby2] = img2[:, bbx1:bbx2, bby1:bby2]\n","            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n","            lb_onehot = lb_onehot * lam + lb2_onehot * (1. - lam)\n","\n","        return {'img':img,'label': lb_onehot}\n","\n","    def __len__(self):\n","        return len(self.dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M8xQv1AXXqpT"},"source":["\n","\n","> utils.py\n","\n"]},{"cell_type":"code","metadata":{"id":"Jr6YA9D-XuuB"},"source":["import numpy as np\n","import torch\n","from torch.nn.modules.module import Module\n","\n","\n","class CutMixCrossEntropyLoss(Module):\n","    def __init__(self, size_average=True):\n","        super().__init__()\n","        self.size_average = size_average\n","\n","    def forward(self, input, target,class_weight):\n","        if len(target.size()) == 1:\n","            target = torch.nn.functional.one_hot(target, num_classes=input.size(-1))\n","            target = target.float().cuda()\n","        return cross_entropy(input, target, self.size_average,class_weight)\n","\n","\n","def cross_entropy(input, target, size_average=True,class_weight=None):\n","    \"\"\" Cross entropy that accepts soft targets\n","    Args:\n","         pred: predictions for neural network\n","         targets: targets, can be soft\n","         size_average: if false, sum is returned instead of mean\n","         class_weight: weights, for weighted Cross Entropy\n","    Examples::\n","        input = torch.FloatTensor([[1.1, 2.8, 1.3], [1.1, 2.1, 4.8]])\n","        input = torch.autograd.Variable(out, requires_grad=True)\n","        target = torch.FloatTensor([[0.05, 0.9, 0.05], [0.05, 0.05, 0.9]])\n","        target = torch.autograd.Variable(y1)\n","        loss = cross_entropy(input, target)\n","        loss.backward()\n","    \"\"\"\n","    if class_weight==None:\n","        class_weight = torch.ones([target.shape[1]], dtype=torch.float32, device='cuda')\n","\n","    logsoftmax = torch.nn.LogSoftmax(dim=1)\n","    if size_average:\n","        return torch.mean(torch.sum(-(target*class_weight) * logsoftmax(input), dim=1)/torch.sum(target*class_weight,dim=1))\n","    else:\n","        return torch.sum(torch.sum(-(target*class_weight) * logsoftmax(input), dim=1)/torch.sum(target*class_weight,dim=1))\n","\n","\n","def onehot(size, target):\n","    vec = torch.zeros(size, dtype=torch.float32)\n","    vec[target] = 1.\n","    return vec\n","\n","\n","def rand_bbox(size, lam):\n","    if len(size) == 4:\n","        W = size[2]\n","        H = size[3]\n","    elif len(size) == 3:\n","        W = size[1]\n","        H = size[2]\n","    else:\n","        raise Exception\n","\n","    cut_rat = np.sqrt(1. - lam)\n","    cut_w = np.int(W * cut_rat)\n","    cut_h = np.int(H * cut_rat)\n","\n","    # uniform\n","    cx = np.random.randint(W)\n","    cy = np.random.randint(H)\n","\n","    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n","    bby1 = np.clip(cy - cut_h // 2, 0, H)\n","    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n","    bby2 = np.clip(cy + cut_h // 2, 0, H)\n","\n","    return bbx1, bby1, bbx2, bby2\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Tb0QyViX45o"},"source":["아래 코드를 필요에 맞게 수정하여 사용하였습니다.\n","\n","Reference: https://github.com/ildoonet/cutmix"]},{"cell_type":"markdown","metadata":{"id":"pGYvmT86VSIs"},"source":["# 1. 사용 Library"]},{"cell_type":"code","metadata":{"id":"twVivVmJTA8u"},"source":["import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from tqdm import tqdm\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n","from torchvision import transforms\n","from efficientnet_pytorch import EfficientNet\n","from sklearn.model_selection import StratifiedKFold\n","from cutmix.cutmix import CutMix\n","from cutmix.utils_ import CutMixCrossEntropyLoss\n","\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5cnCVEgmVdua"},"source":["# 2. DataSet and Data augmentation"]},{"cell_type":"code","metadata":{"id":"SvTfn7kNTFJY"},"source":["class CustomDataset(Dataset):\n","    def __init__(self, files, labels=None, mode='train', transform=None):\n","        self.mode = mode\n","        self.files = files\n","        if mode == 'train':\n","            self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def __getitem__(self, i):\n","        if self.mode == 'train':\n","            img = Image.open('train_imgs/' + self.files[i])\n","\n","            if self.transform:\n","                img = self.transform(img)\n","\n","            return {\n","                'img': torch.tensor(img, dtype=torch.float32).clone().detach(),\n","                'label': torch.tensor(self.labels[i], dtype=torch.long)\n","            }\n","        else:\n","            img = Image.open('test_imgs/' + self.files[i])\n","            if self.transform:\n","                img = self.transform(img)\n","\n","            return {\n","                'img': torch.tensor(img, dtype=torch.float32).clone().detach(),\n","            }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X0ZjoQ0kV2I9"},"source":["학습 시에만 데이터를 증강하도록 하기 위해 Transform을 두가지로 하였습니다.\n"]},{"cell_type":"code","metadata":{"id":"5LwjMMs3TH7_"},"source":["mytransform = transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.RandomCrop(244),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomVerticalFlip(),\n","    transforms.RandomRotation(degrees=(0, 360)),\n","    transforms.RandomPerspective(),\n","    transforms.ToTensor(),\n","])\n","\n","myvaltransform =transforms.Compose([\n","    transforms.Resize((256, 256)),\n","    transforms.ToTensor(),\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"93BzzSWZWI54"},"source":["# 3. Model"]},{"cell_type":"code","metadata":{"id":"ajNvSlDSTLqS"},"source":["class CNN_Model(nn.Module):\n","    def __init__(self, class_n, rate=0.2):\n","        super(CNN_Model, self).__init__()\n","        self.model = EfficientNet.from_pretrained('efficientnet-b7')\n","        self.dropout = nn.Dropout(rate)\n","        self.output_layer = nn.Linear(in_features=1000, out_features=class_n, bias=True)\n","\n","    def forward(self, inputs):\n","        output = self.output_layer(self.dropout(self.model(inputs)))\n","        return output\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9FCruW3-WfTF"},"source":["# 4. Train & Inference"]},{"cell_type":"code","metadata":{"id":"1ooG7NAiTNa-"},"source":["def train_step(model, batch_item, epoch, batch, training,class_weight=None):\n","    img = batch_item['img'].to(device)\n","    label = batch_item['label'].to(device)\n","    if training is True:\n","        model.train()\n","        optimizer.zero_grad()\n","        with torch.cuda.amp.autocast():\n","            output = model(img)\n","            loss = criterion(output, label,class_weight=class_weight)\n","        loss.backward()\n","        optimizer.step()\n","\n","        return loss\n","    else:\n","        model.eval()\n","        with torch.no_grad():\n","            output = model(img)\n","            loss = criterion(output, label,class_weight=class_weight)\n","            \n","def predict(models,dataset):\n","    for fold,model in enumerate(models):\n","        model.eval()\n","    tqdm_dataset = tqdm(enumerate(dataset))\n","    training = False\n","    results = []\n","    for batch, batch_item in tqdm_dataset:\n","        img = batch_item['img'].to(device)\n","        for fold,model in enumerate(models):\n","            with torch.no_grad():\n","                if fold ==0:\n","                    output = model(img)\n","                else:\n","                    output = output+model(img)\n","        output = 0.2*output\n","        output = torch.tensor(torch.argmax(output, axis=-1), dtype=torch.int32).cpu().numpy()\n","        results.extend(output)\n","    return results"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FdEqOe-vWs3q"},"source":["# 5. Main Sequence"]},{"cell_type":"markdown","metadata":{"id":"8KZhk9VddBla"},"source":[" - Setting"]},{"cell_type":"code","metadata":{"id":"B2fNN3F5TRiZ"},"source":["if __name__ == '__main__':\n","    # Load Data\n","    train_total = pd.read_csv('train.csv')\n","    test = pd.read_csv('test.csv')\n","    # Hyperparameter Setting\n","    device = torch.device(\"cuda\")\n","    batch_size = 8\n","    class_n = len(train_total['disease_code'].unique())\n","    learning_rate = 2e-4\n","    epochs = 300\n","    folds = 5\n","    random_seed=100\n","    save_path = 'models/model.'\n","    # Cross Validation\n","    kfold = StratifiedKFold(n_splits=folds,shuffle=True,random_state=random_seed)\n","    # Loss Weights\n","    class_weight=torch.FloatTensor(1/train_total['disease_code'].value_counts()).cuda()\n","\n","    torch.manual_seed(random_seed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QMrOGRfIdHEw"},"source":[" - Dataset"]},{"cell_type":"code","metadata":{"id":"C3YmLULCctAg"},"source":["    train_dataset = CustomDataset(train_total['img_path'].str.split('/').str[-1].values, train_total['disease_code'].values,\n","                                  transform=mytransform)\n","    train_dataset = CutMix(train_dataset,num_class=7,beta=1.0,prob=0.5,num_mix=2)\n","    valid_dataset = CustomDataset(train_total['img_path'].str.split('/').str[-1].values, train_total['disease_code'].values,\n","                                  transform=myvaltransform)\n","    test_dataset = CustomDataset(test['img_path'].str.split('/').str[-1], labels=None, mode='test',\n","                                 transform=myvaltransform)\n","\n","    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=3, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YvssvsKedJ8H"},"source":[" - Train\n"]},{"cell_type":"code","metadata":{"id":"8E1EDx-Qcy08"},"source":["    k_loss_plot, k_val_loss_plot = [], []    \n","    for fold,(train_idx,valid_idx) in enumerate(kfold.split(train_dataset,train_total[\"disease_code\"])):\n","        train_subsampler = SubsetRandomSampler(train_idx)\n","        valid_subsampler = SubsetRandomSampler(valid_idx)\n","\n","        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=3, sampler=train_subsampler)\n","        val_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, num_workers=3, sampler=valid_subsampler)\n","\n","        model = CNN_Model(class_n).to(device)\n","        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","        criterion = CutMixCrossEntropyLoss(True)\n","\n","        loss_plot, val_loss_plot = [], []\n","        # Training\n","        for epoch in range(epochs):\n","            total_loss, total_val_loss = 0, 0\n","            tqdm_dataset = tqdm(enumerate(train_dataloader))\n","            training = True\n","            for batch, batch_item in tqdm_dataset:\n","                batch_loss = train_step(model,batch_item, epoch, batch, training,class_weight=class_weight)\n","                total_loss += batch_loss\n","\n","                tqdm_dataset.set_postfix({\n","                    'Epoch': epoch + 1,\n","                    'Loss': '{:06f}'.format(batch_loss.item()),\n","                    'Total Loss': '{:06f}'.format(total_loss / (batch + 1))\n","                })\n","            loss_plot.append((total_loss / (batch + 1)).cpu().item())\n","\n","            tqdm_dataset = tqdm(enumerate(val_dataloader))\n","            training = False\n","            for batch, batch_item in tqdm_dataset:\n","                batch_loss = train_step(model,batch_item, epoch, batch, training)\n","                total_val_loss += batch_loss\n","\n","                tqdm_dataset.set_postfix({\n","                    'Epoch': epoch + 1,\n","                    'Val Loss': '{:06f}'.format(batch_loss.item()),\n","                    'Total Val Loss': '{:06f}'.format(total_val_loss / (batch + 1))\n","                })\n","            val_loss_plot.append((total_val_loss / (batch + 1)).cpu().item())\n","\n","            if np.min(val_loss_plot) == val_loss_plot[-1]:\n","                torch.save(model.state_dict(), save_path+str(fold)+\".pt\")\n","\n","        k_loss_plot.append(min(loss_plot))\n","        k_val_loss_plot.append(min(val_loss_plot))\n","\n","    print(\"Train Loss: \",np.mean(k_loss_plot),\", Valid Loss: \",np.mean(k_val_loss_plot))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-hTBkm0xdPm-"},"source":[" - Inference"]},{"cell_type":"code","metadata":{"id":"7Cwx_5cxTVWw"},"source":["    models = []\n","    for i in range(5):\n","        model = CNN_Model(class_n).to(device)\n","        model.load_state_dict(torch.load(save_path+str(i)+\".pt\"))\n","        models.append(model)\n","    preds = predict(models,test_dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pe90-pnTdVKm"},"source":[" - Submission\n"," "]},{"cell_type":"code","metadata":{"id":"Dkjr69ridNPm"},"source":["    submission = pd.read_csv('sample_submission.csv')\n","    submission.iloc[:, 1] = preds\n","    submission.to_csv('submission.csv', index=False)"],"execution_count":null,"outputs":[]}]}